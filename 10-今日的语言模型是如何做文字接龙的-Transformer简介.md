# 10-今日的语言模型是如何做文字接龙的——Transformer简介


## 🪜 语言模型-演进历史

```
N-gram → Feed-forward Network → RNN → Transformer → ChatGPT
```

---

## 🧩 语言模型-架构概览

![image](https://github.com/Vincia-Jun/GENERATIVE-AI-2024-SPRING-NOTEs/blob/main/Figs/10-%E4%BB%8A%E6%97%A5%E7%9A%84%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%98%AF%E5%A6%82%E4%BD%95%E5%81%9A%E6%96%87%E5%AD%97%E6%8E%A5%E9%BE%99%E7%9A%84-Transformer%E7%AE%80%E4%BB%8B-00.png)

---


## 🧬 语言模型-架构细节

![image](https://github.com/Vincia-Jun/GENERATIVE-AI-2024-SPRING-NOTEs/blob/main/Figs/10-%E4%BB%8A%E6%97%A5%E7%9A%84%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%98%AF%E5%A6%82%E4%BD%95%E5%81%9A%E6%96%87%E5%AD%97%E6%8E%A5%E9%BE%99%E7%9A%84-Transformer%E7%AE%80%E4%BB%8B-01.png)

---

## 🧾 课堂小结

本节课程从语言模型的基本工作原理出发，引入了 Transformer 架构在文本生成中的关键作用。通过简化讲解，我们了解了从 Transformer 到语言模型的内部运作原理，重点是理解上述的两张图。需要注意的是，本节内容刻意避开了复杂的数学与技术细节，着重帮助我们建立对 Transformer 工作机制的直观认知，为后续深入学习打下了良好的基础。

---



## 📚 拓展资料
| 说明🔎   | 链接🔗 | 重要⭐ | TODO✅ |
|--------|----------|--------|--------|
| 语言模型的演进史 | [视频地址](https://www.youtube.com/watch?v=dymfkWtVUdo)| ⭐⭐ |
| Transformer-视频详解（上） | [视频地址](https://www.youtube.com/watch?v=n9TlOhRjYoc)| ⭐⭐⭐⭐ |
| Transformer-视频详解（下） | [视频地址](https://www.youtube.com/watch?v=N6aRv06iv2g)| ⭐⭐⭐⭐ |
| Attention Is All You Need | [论文地址](https://arxiv.org/abs/1706.03762)| ⭐⭐⭐ | 
