# 01-80分钟快速了解大型语言模型

## Ⅰ，ChatGPT 的基本原理
- **ChatGPT** = Chat + G (Generative) + P (Pre-trained) + T (Transformer)
- **文字接龙：** Next Token Prediction 是 ChatGPT 的核心原理，即通过预测未完成句子的下一个字来生成文本。例如，输入“台湾大”，它会预测接下来可能是“学”、“哥”等字，并将置信度转为概率分布选择输出字。
- **文本令牌：** Token 是文字接龙的基本单位，每个模型的 Token 划分方式不同。Token 必须能够穷举，比如单词无法穷举，但词根词缀是可以穷举的（unkillable → un、kill、able）。

![image](https://github.com/Vincia-Jun/GENERATIVE-AI-2024-SPRING-NOTEs/blob/main/Figs/01-80%E5%88%86%E9%92%9F%E5%BF%AB%E9%80%9F%E4%BA%86%E8%A7%A3%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B-00.png)

## Ⅱ，GPT 发展历程
| 模型   | 发布时间 | 参数量（天资）   | 数据量（努力）   | 主要特点                     |
|--------|----------|----------|----------|--------------------------|
| GPT-1  | 2018     | 117M     | 1G      |  仅限于简单文本生成        |
| GPT-2  | 2019     | 1.5B     | 40GB    | 可以进行基本的问答与摘要           |
| GPT-3  | 2020     | 175B     | 580GB   | 能够生成较复杂的文章，代码等   |
| GPT-4  | 2023     | 未公开   | 未公开   | 多模态对齐人类需求，更强的推理能力  |

- GPT-3 虽然能力强，但由于只从互联网学习，容易生成非预期的内容。
- GPT-3 效果差强人意，2020年许多人认为 OpenAI 走错了方向。

## Ⅲ，GPT 训练机制
- **预训练（Pre-training）：** 使用自监督的方法，在大规模互联网文本数据上学习文字接龙，让模型拥有广泛的知识。
- **监督微调（Supervised Fine-tuning, SFT）：** 通过人类标注数据调整模型输出，无需大量资料，画龙点睛之笔。
- **强化学习（Reinforcement Learning from Human Feedback, RLHF:）：** 通过人类反馈 or 训练奖励模型优化模型偏好。

![image](https://github.com/Vincia-Jun/GENERATIVE-AI-2024-SPRING-NOTEs/blob/main/Figs/01-80%E5%88%86%E9%92%9F%E5%BF%AB%E9%80%9F%E4%BA%86%E8%A7%A3%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B-01.png)

## Ⅳ，GPT 应用技巧
- 明确需求、提供背景信息、提供示例。
- 鼓励 ChatGPT 进行思考（COT）、寻找和使用一些神奇咒语、引导进行反省。
- 拆解任务，进行自主规划。

⚠️给教授看论文前没有用 GPT 润色是一个失礼的行为！

## Ⅴ，课堂小结
ChatGPT 及其背后的 GPT 系列是基于 Transformer 结构的大型语言模型，通过预训练、监督微调和强化学习，使其逐步学习更符合人类需求的回答方式。为了提升模型能力，可以利用提示词优化、任务拆解和自主规划等方法。此外，未来 AI 可能具备更强的自我优化能力，与现实世界的交互也将更加紧密。

## Ⅵ，拓展资料
| 说明🔎   | 链接🔗 | 重要⭐ | TODO✅ |
|--------|----------|--------|--------|
| 理解文字接龙为什么要掷骰子？|   [论文地址](https://arxiv.org/abs/1904.09751)         | ⭐ |
| 理解 GPT-2 性能表现  | [网页地址](https://openai.com/index/better-language-models) | ⭐ |
| 理解 GPT-3 性能表现  | [论文地址](https://arxiv.org/abs/2005.14165)                | ⭐ |
| InstructGPT-监督微调 | [论文地址](https://arxiv.org/abs/2203.02155)  | ⭐⭐⭐ |
| 跨语种学习的涌现能力 | [论文地址](https://arxiv.org/abs/1909.09587)  | ⭐ |
| GPT-4 技术报告 | [论文地址](https://arxiv.org/abs/2303.08774) | ⭐⭐⭐ |
| 提示词工程：CoT | [论文地址](https://arxiv.org/abs/2205.11916) | ⭐⭐⭐⭐ |
| 提示词工程：Engineers | [论文地址](https://arxiv.org/abs/2211.01910) | ⭐ |
| 提示词工程：Generate Prompts | [论文地址](https://arxiv.org/abs/2206.03931) | ⭐ |
| 提示词工程：Optimizers | [论文地址](https://arxiv.org/abs/2309.03409) | ⭐ |
| 创作长篇小说：如何拆解任务 | [论文地址](https://arxiv.org/abs/2210.06774) | ⭐ |
| 反思能力：隐式反思避免有害信息 | [论文地址](https://arxiv.org/abs/2212.08073) | ⭐⭐⭐⭐⭐ |
| 反思能力：两个智能体对话博弈 | [论文地址](https://arxiv.org/abs/2303.17071) | ⭐⭐⭐⭐⭐ |
| 交互：Language Models as Zero-Shot Planners | [论文地址](https://arxiv.org/abs/2201.07207) | ⭐⭐⭐⭐⭐ |
| 交互：Embodied Reasoning through Planning with LLMs | [论文地址](https://arxiv.org/abs/2207.05608) | ⭐⭐⭐⭐⭐ |
| GPT-Tokenizer  | [网页地址](https://platform.openai.com/tokenizer)  | ⭐ |
| 强化学习教程 | [视频地址](https://www.youtube.com/watch?v=XWukX-ayIrs&list=PLJV_el3uVTsMhtt7_Y6sgTHGHp1Vb2P2J&index=30)| ⭐⭐⭐⭐ |
| ChatGPT 原理剖析 | [视频地址](https://www.youtube.com/watch?v=yiY4nPOzJEg&list=PLJV_el3uVTsOePyfmkfivYZ7Rqr2nMk3W&index=2) | ⭐⭐⭐⭐ |
