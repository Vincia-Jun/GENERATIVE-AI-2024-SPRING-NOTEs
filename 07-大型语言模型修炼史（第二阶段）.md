# 07-大型语言模型修炼史（第二阶段：名师指点，发挥潜力）

## Ⅰ，大型语言模型的修炼阶段

- 第一阶段：自我学习，累积实力。模型通过海量网络数据进行预训练，积累语言知识。
  
- 第二阶段：名师指点，发挥潜力。人类老师通过监督学习（督导式学习）对模型进行指导，设计期望的对话示例作为学习数据。

- 第三阶段：参与实战，打磨技巧。使用符合人类偏好的数据进行微调。

## Ⅱ，督导式学习策略

- **构建角色对话：** 通过在输入中标明 “USER” 与 “AI” 的角色，构建对话场景，确保文字接龙符合预期。

  - 输入：“USER: 台湾最高的山是哪座？ AI:” → 输出：“玉山[END]” ✅
 
  - 输入：“台湾最高的山是哪座？玉山” → 输出：“是的[END]” ❌

- **标注成本高昂：** 标注过程中需要大量人力，但数据量有限，因此仅能覆盖部分情况（如遇到“最”时回答“玉山”）。

- **使用预训练模型参数；** 督导学习依赖少量的高质量问答数据对，如果仅仅依靠这一过程优化整个模型的最佳参数，难以有效学习到海量的知识。因此，用海量互联网数据进行预训练是大模型学习到通用知识的必经过程，无法用督导学习的数据进行代替。

- **使用 Adapter 微调技术：** 通过引入不同的 Adapter 模块（如 LoRA 等）对模型进行局部调整，使得模型在不大幅修改预训练参数的情况下，实现特定任务的优化。

![image](https://github.com/Vincia-Jun/GENERATIVE-AI-2024-SPRING-NOTEs/blob/main/Figs/07-%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%BF%AE%E7%82%BC%E5%8F%B2%EF%BC%88%E7%AC%AC%E4%BA%8C%E9%98%B6%E6%AE%B5%EF%BC%89-00.png)

## Ⅲ，Fine-tuning 的效果

- InstructGPT、LLaMA-2、LIMA 都强调过："Less Is More for Alignment", "Quality is All You Need" 等观点。

- Instruction Fine-tuning 确乎是画龙点睛之笔。

- 模型在经过单一任务的训练后，能够自动迁移学习其他语言的相似任务。

- 多语言预训练有助于提升模型的跨语言迁移能力和整体泛化性能。


## Ⅳ，Fine-tuning 的路线

- 路线一：打造**一堆专才**。分别训练翻译专家、编修专家等单一任务模型，每个模型仅针对特定任务进行优化，训练数据较为单一。
  - Bert 通过 Fine-tuning 打造一堆专才。

- 路线二：打造**一个通才**。收集涵盖各类任务的大量标注数据，训练一个多功能模型，支持翻译、摘要、文法检查、邮件撰写等多种任务。
  - "Scaling Instruction-Finetuned Language Models" 使用 1.8K 个任务场景的问答数据打造通才模型。
  - 数据质量也很重要，FLAN 是基于语料构造的模板数据，InstructGPT 基于真实的对话数据，效果更好。

![image](https://github.com/Vincia-Jun/GENERATIVE-AI-2024-SPRING-NOTEs/blob/main/Figs/07-%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%BF%AE%E7%82%BC%E5%8F%B2%EF%BC%88%E7%AC%AC%E4%BA%8C%E9%98%B6%E6%AE%B5%EF%BC%89-01.png)

## Ⅴ，Fine-tuning 走入千万家
- 初始权重：使用 LLaMA 等开源模型的预训练权重。

- 微调数据：可以引导 GPT 逆向工程产生的对话数据。

- 从 LLaMA 开源那一刻，整个世界被解放了，带来了 Alpaca，Vicuna 等模型，LLaMA 子子孙孙开始开枝散叶，飞去平常百姓家。

![image](https://github.com/Vincia-Jun/GENERATIVE-AI-2024-SPRING-NOTEs/blob/main/Figs/07-%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%BF%AE%E7%82%BC%E5%8F%B2%EF%BC%88%E7%AC%AC%E4%BA%8C%E9%98%B6%E6%AE%B5%EF%BC%89-02.png)

## Ⅵ，课堂小结
本次课件详细介绍了大型语言模型从预训练到 fine-tuning 的全流程，重点在于如何利用预训练参数作为基础，通过不同的策略（专才与通才路线）进一步提升模型能力。这些方法和技术为未来的模型应用和个性化定制提供了坚实基础，标志着人人都可以 fine-tune 大型语言模型的时代已经到来。
  

## Ⅶ，拓展资料
| 说明🔎   | 链接🔗 | 重要⭐ | TODO✅ |
|--------|----------|--------|--------|
| Adapters 使用文档 | [网页地址](https://adapterhub.ml/) | ⭐⭐⭐⭐ |
| 语言模型在多语言语料的举一反三能力 | [论文地址](https://arxiv.org/abs/1909.09587) | ⭐ |
| Bert 如何通过 Fine-tuning 打造一堆专才 | [网页地址](https://www.youtube.com/watch?v=gh0hewYkjgo) | ⭐⭐⭐ |
| 通往通才的研究：语言模型如何复习学习过的知识？ | [论文地址](https://arxiv.org/abs/1909.03329v2) | ⭐⭐⭐ |
| 通往通才的研究：FLAN | [论文地址](https://arxiv.org/abs/2109.01652) | ⭐ |
| 通往通才的研究：T0 | [论文地址](https://arxiv.org/abs/2110.08207) | ⭐ |
| 通往通才的研究：在更大量的任务(1.8K)中进行 Fine-tuning | [论文地址](https://arxiv.org/abs/2210.11416) | ⭐⭐⭐ |
| Instruction Fine-tuning 是画龙点睛：InstructGPT | [论文地址](https://arxiv.org/abs/2203.02155) | ⭐ |
| Instruction Fine-tuning 是画龙点睛：Llama-2 | [论文地址](https://arxiv.org/abs/2307.09288) | ⭐ |
| Instruction Fine-tuning 是画龙点睛：LIMA | [论文地址](https://arxiv.org/abs/2305.11206) | ⭐ |
| 逆向工程构造微调数据-1 | [论文地址](https://arxiv.org/abs/2305.15717) | ⭐ |
| 逆向工程构造微调数据-2 | [论文地址](https://arxiv.org/abs/2212.10560) | ⭐ |
| 开源预训练基座：LLaMA-1 | [论文地址](https://arxiv.org/abs/2212.10560) | ⭐ |
| 开源预训练基座：LLaMA-2 | [论文地址](https://arxiv.org/abs/2307.09288) | ⭐ |
| LLaMA → Alpaca | [网页地址](https://crfm.stanford.edu/2023/03/13/alpaca.html) | ⭐ |
| LLaMA → Vicuna | [网页地址](https://lmsys.org/blog/2023-03-30-vicuna/) | ⭐ |
| A Survey of Large Language Models | [论文地址](https://arxiv.org/abs/2303.18223) | ⭐⭐⭐⭐⭐ |




