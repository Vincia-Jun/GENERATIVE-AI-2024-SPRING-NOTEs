# 🧠 15 浅谈生成式人工智能的生成策略 · 课堂笔记


## 🧭 一、课程导语

生成式人工智能（Generative AI）可以生成具结构的复杂内容，例如文字、图像、声音等。这些内容虽看似无限多样，实则是由有限的基本单元（如 Token、Pixel、Sample）组合而成。

- 文字：由 Token 构成（如 LLaMA 2 拥有 32K token vocabulary）

- 图像：由 Pixel 构成，颜色精度取决于 bit-depth

- 声音：由 Sample 构成，受采样率与位深影响

---

## 🔄 二、Autoregressive Generation（AR）策略

### 📚 2.1 定义与机制

- 逐个生成内容单元（token/pixel/sample）

- 每一步依赖前一步生成的结果

- 应用广泛：文字生成（ChatGPT、GPT-4）、图像（Image-GPT）、声音（WaveNet）

- 🔗图像生成论文：《[Image-GPT: Generative Pretraining from Pixel](https://openai.com/index/image-gpt/)》

- 🔗声音生成论文：《[WaveNet: A Generative Model for Raw Audio](https://arxiv.org/abs/1609.03499)》


### 🧱 2.2 局限性

- 无法并行，每个位置都依赖于前一个位置的生成结果

- 计算代价高：

  - 一张 1024×1024 图像 ≈ 100 万次接龙
  - 一段 22K 采样率 1 分钟音频 ≈ 132 万次接龙

---

## ⚡ 三、Non-Autoregressive Generation（NAR）策略

### 💡 3.1 特点

- 所有位置同时生成，可大幅提升速度

- 《[A Survey on Non-Autoregressive Generation for Neural Machine Translation and Beyond](https://arxiv.org/abs/2204.09269)》


### 🤖 3.2 面临挑战

- 生成往往需要 AI 自行脑补，给定条件仍有很多不同可能的输出

- 易出现多模态问题（Multi-modality Problem）：
  - 相同条件下可能生成不一致或无逻辑的结果
  - 模型在不同位置“各自发挥”，产生“四不像”的内容

### 📉 3.3 示例问题

- 文本生成中：“李宏毅是” → 可能出现“教授”“演员”“演艺圈的人”等不同补全
- 图像生成中：一只“奔跑的狗”可能变成“哈士奇 + 草原 + 向左 + 黑色”的混合物

---

## 🔁 四、混合生成策略：AR + NAR 结合

### 🧬 4.1 串行思路

- 先用 Autoregressive 生成一个粗略版本，再用 NAR 补全细节

- 实现方式：AutoEncoder（先压缩后解压），先使用 Autoregressive 将输入条件编码，随后使用 NAR 解码

- 图像：《[MaskGIT: Masked Generative Image Transformer](https://arxiv.org/abs/2202.04200)》

- 语音：《[Towards audio language modeling -- an overview](https://arxiv.org/abs/2402.13236v1)》

### 🧱 4.2 融合思路

- Autoregressive Generation ≈ NAR + NAR + NAR + ... + NAR

- NAR 并行生成容易导致不一致性，而对于 4x4 图像生成任务和 1024x1024 图像生成任务来说，前者的约束性会更强，不一致性相对更低。这种关键启示告诉我们，NAR 不适合直接处理端到端的任务，但可以通过分阶段的设计保证每次 NAR 仅需处理少量的生成任务。

- 从小图 → 大图：4x4 → 16x16 → 64x64 ...
    - 《[Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding](https://arxiv.org/abs/2205.11487)》
    - 《[Progressive Growing of GANs for Improved Quality, Stability, and Variation](https://arxiv.org/abs/1710.10196)》

- 从噪声图 → 清晰图（Diffusion Model）：《[Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2006.11239)》

- 多阶段修补图像错误区域（Inpainting）：《[MaskGIT: Masked Generative Image Transformer](https://arxiv.org/abs/2202.04200)》


### 📊 4.3 策略比较

| 特性       | Autoregressive, AR             | Non-autoregressive, NAR         |
|------------|--------------------------------|----------------------------------|
| 特性       | 按部就班、各个击破             | 齐头并进、一次到位               |
| 速度       | —                              | 胜                              |
| 品质       | 胜                              | —                               |
| 应用       | 常用于文字                      | 常用于影像                      |


---

## 🧾 课堂小结

Autoregressive（AR）策略以串行方式逐个生成内容单元，确保每一步都基于前文上下文，具备较强的一致性与连贯性；而 Non-Autoregressive（NAR）策略则采用并行生成，依据初始条件同时产出全部结果，速度更快但易出现语义跳跃或内容不协调的问题。生成高质量结果的核心在于控制生成过程中的上下文一致性，因此，如何设计机制使 NAR 在齐头并进时依然保持语义连贯，是理解本节策略对比的关键。
